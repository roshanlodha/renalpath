{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21369bf1-4a02-4a26-946c-8ff7c17a68d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading data...\n",
      "Detected 6 classes: ['Angiomyolipoma' 'Chromophobe' 'Clear_cell' 'Hybrid' 'Oncocytoma'\n",
      " 'Papillary'].\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import vit_h_14, ViT_H_14_Weights\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "# === Parameters ===\n",
    "working_dir = \"/data/lodhar2/milan\"\n",
    "os.chdir(working_dir)\n",
    "TRAIN_PATH = \"data/vit_train.npz\"\n",
    "VAL_PATH = \"data/vit_val.npz\"\n",
    "BATCH_SIZE = 1\n",
    "EPOCHS = 20\n",
    "PATIENCE = 5\n",
    "SEED = 42\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# === Reproducibility ===\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# === Load preprocessed data ===\n",
    "print(\"Loading data...\")\n",
    "train_data = np.load(TRAIN_PATH)\n",
    "val_data = np.load(VAL_PATH)\n",
    "\n",
    "X_train = torch.tensor(train_data[\"images\"]).float()\n",
    "X_val = torch.tensor(val_data[\"images\"]).float()\n",
    "\n",
    "# === Map string labels to integers ===\n",
    "unique_labels = np.unique(train_data[\"labels\"])\n",
    "label_to_idx = {label: i for i, label in enumerate(unique_labels)}\n",
    "\n",
    "y_train = torch.tensor([label_to_idx[label] for label in train_data[\"labels\"]]).long()\n",
    "y_val = torch.tensor([label_to_idx[label] for label in val_data[\"labels\"]]).long()\n",
    "\n",
    "num_classes = len(torch.unique(y_train))\n",
    "print(f\"Detected {num_classes} classes: {unique_labels}.\")\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32c94424-0538-4382-8be1-d8685095f45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ViT-H-14...\n"
     ]
    }
   ],
   "source": [
    "# === Top-K accuracy ===\n",
    "def top_k_accuracy(y_true, y_probs, k=2):\n",
    "    top_k_preds = np.argsort(y_probs, axis=1)[:, -k:]\n",
    "    correct = sum(label in top_k for label, top_k in zip(y_true, top_k_preds))\n",
    "    return correct / len(y_true)\n",
    "\n",
    "# === Define model ===\n",
    "print(\"Loading ViT-H-14...\")\n",
    "weights = ViT_H_14_Weights.IMAGENET1K_SWAG_E2E_V1\n",
    "model = vit_h_14(weights=weights)\n",
    "\n",
    "# Replace head\n",
    "in_features = model.heads[-1].in_features\n",
    "model.heads = nn.Linear(in_features, num_classes)\n",
    "model.to(DEVICE)\n",
    "\n",
    "# === Loss and optimizer ===\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4485932-216e-49fb-9330-a5f670d7624e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/20 - Training Loss: 2.3485\n",
      "Validation Balanced Accuracy: 0.1667 | Top-2 Accuracy: 0.4091\n",
      "New best model saved.\n",
      "\n",
      "Epoch 2/20 - Training Loss: 1.9910\n",
      "Validation Balanced Accuracy: 0.1771 | Top-2 Accuracy: 0.2727\n",
      "\n",
      "Epoch 3/20 - Training Loss: 1.9517\n",
      "Validation Balanced Accuracy: 0.1553 | Top-2 Accuracy: 0.1773\n",
      "\n",
      "Epoch 4/20 - Training Loss: 1.9403\n",
      "Validation Balanced Accuracy: 0.1595 | Top-2 Accuracy: 0.2818\n",
      "\n",
      "Epoch 5/20 - Training Loss: 1.7836\n",
      "Validation Balanced Accuracy: 0.1523 | Top-2 Accuracy: 0.3727\n",
      "\n",
      "Epoch 6/20 - Training Loss: 1.7581\n"
     ]
    }
   ],
   "source": [
    "# === Training loop ===\n",
    "best_top2_acc = 0\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"\\nEpoch {epoch+1}/{EPOCHS} - Training Loss: {running_loss / len(train_loader):.4f}\")\n",
    "\n",
    "    # === Validation ===\n",
    "    model.eval()\n",
    "    all_probs, all_preds, all_labels = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "            probs = torch.softmax(outputs, dim=1).cpu().numpy()\n",
    "            preds = np.argmax(probs, axis=1)\n",
    "            all_probs.append(probs)\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.numpy())\n",
    "\n",
    "    all_probs = np.concatenate(all_probs, axis=0)\n",
    "    all_labels = np.array(all_labels)\n",
    "    bal_acc = balanced_accuracy_score(all_labels, all_preds)\n",
    "    top2_acc = top_k_accuracy(all_labels, all_probs, k=2)\n",
    "\n",
    "    print(f\"Validation Balanced Accuracy: {bal_acc:.4f} | Top-2 Accuracy: {top2_acc:.4f}\")\n",
    "\n",
    "    scheduler.step(top2_acc)\n",
    "\n",
    "    if top2_acc > best_top2_acc:\n",
    "        best_top2_acc = top2_acc\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), \"best_vit.pt\")\n",
    "        print(\"New best model saved.\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= PATIENCE:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4903972-fac9-487b-8d52-ffa8af8db9b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python/3.10",
   "language": "python",
   "name": "py3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
