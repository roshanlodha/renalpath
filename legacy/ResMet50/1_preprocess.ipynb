{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90ab67ad-4f0a-4962-877d-6458375c3ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding image path\n",
      "removing rows with missing images\n",
      "\n",
      "Class\n",
      "Clear_cell        149\n",
      "Papillary          94\n",
      "Hybrid             81\n",
      "Oncocytoma         43\n",
      "Chromophobe        42\n",
      "Angiomyolipoma     31\n",
      "Name: count, dtype: int64\n",
      "cleaning dataframe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Class\n",
       "Clear_cell        149\n",
       "Papillary          94\n",
       "Hybrid             81\n",
       "Oncocytoma         43\n",
       "Chromophobe        42\n",
       "Angiomyolipoma     31\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "import os\n",
    "\n",
    "# === Load raw data ===\n",
    "working_dir = \"/data/lodhar2/milan\"\n",
    "os.chdir(working_dir)\n",
    "data = pd.read_csv(f\"{working_dir}/data.csv\", dtype=str)\n",
    "\n",
    "# === Construct image paths ===\n",
    "print(\"adding image path\")\n",
    "data['img_path'] = (\n",
    "    \"Images/\" +\n",
    "    data['Patient ID'].str.zfill(4) + \"_\" +\n",
    "    data['Date'] + \"_\" +\n",
    "    data['Image ID'].str.zfill(2) + \".png\"\n",
    ")\n",
    "data['img_path'] = data['img_path'].astype(str)\n",
    "\n",
    "# === Filter out rows with missing image files ===\n",
    "print(\"removing rows with missing images\")\n",
    "data = data[data['img_path'].apply(lambda x: os.path.exists(x))].reset_index(drop=True)\n",
    "print(f\"\\n{data['Class'].value_counts()}\")\n",
    "\n",
    "# === Drop unused columns ===\n",
    "print(\"cleaning dataframe\")\n",
    "data = data.drop(columns=['Patient Name', 'MRN', 'Nephrectomy Approach', 'Path note', 'Notes'])\n",
    "\n",
    "# === One vs Rest predictor ===\n",
    "# print(\"removing 'Hybrid' class\")\n",
    "# data = data[data['Class'] != \"Hybrid\"]\n",
    "data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47784758-2c70-4bc2-80cf-f2e36add0d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting non-Chromophobe classes to 'Other'\n",
      "filtering rare classes\n",
      "stratifying dataset\n"
     ]
    }
   ],
   "source": [
    "hoi = \"Chromophobe\"\n",
    "print(f\"converting non-{hoi} classes to 'Other'\")\n",
    "data['Class'] = data['Class'].apply(lambda x: hoi if x == hoi else \"Other\")\n",
    "\n",
    "# === Filter out rare classes (<10 instances) ===\n",
    "print(\"filtering rare classes\")\n",
    "value_counts = data['Class'].value_counts()\n",
    "low_count_types = value_counts[value_counts < 10].index.tolist()\n",
    "filtered_data = data[~data['Class'].isin(low_count_types)].drop(columns=['Pathology']).reset_index(drop=True)\n",
    "\n",
    "filtered_data_cleaned = filtered_data[\n",
    "    filtered_data['Class'].notna() &\n",
    "    filtered_data['img_path'].apply(lambda x: os.path.exists(x))\n",
    "]\n",
    "\n",
    "# === Stratified train/val split ===\n",
    "print(\"stratifying dataset\")\n",
    "train_df, val_df = train_test_split(\n",
    "    filtered_data_cleaned,\n",
    "    test_size=0.5,\n",
    "    stratify=filtered_data_cleaned[\"Class\"],\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "816d2866-4575-411d-af86-d1c2eebfebed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upsampling minority classes\n",
      "adding train-validation labels\n",
      "saving balanced, filtered dataframe\n"
     ]
    }
   ],
   "source": [
    "# === Upsample training set to balance classes ===\n",
    "print(\"upsampling minority classes\")\n",
    "df_list = []\n",
    "max_class_size = train_df[\"Class\"].value_counts().max()\n",
    "\n",
    "for label in train_df[\"Class\"].unique():\n",
    "    subset = train_df[train_df[\"Class\"] == label]\n",
    "    upsampled = resample(\n",
    "        subset,\n",
    "        replace=True,\n",
    "        n_samples=max_class_size,\n",
    "        random_state=42\n",
    "    )\n",
    "    df_list.append(upsampled)\n",
    "\n",
    "train_upsampled = pd.concat(df_list)\n",
    "\n",
    "# === Add 'split' column and combine ===\n",
    "print(\"adding train-validation labels\")\n",
    "train_upsampled[\"split\"] = \"train\"\n",
    "val_df[\"split\"] = \"val\"\n",
    "final_df = pd.concat([train_upsampled, val_df]).reset_index(drop=True)\n",
    "\n",
    "# === Save to CSV ===\n",
    "print(\"saving balanced, filtered dataframe\")\n",
    "final_df.to_csv(f\"{working_dir}/data/split_balanced_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2907ca9c-2547-4fdb-96a4-8ed4c3603f71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python/3.10",
   "language": "python",
   "name": "py3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
